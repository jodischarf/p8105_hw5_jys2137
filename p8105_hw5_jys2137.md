Homework 5
================
jys2137
11/19/2021

The purpose of this file is to present the answers to Homework 5, an
assignment reinforcing ideas in the **Iteration** topic for P8105.

## Contents

**Problem 1**

-   **1.1.** Data import
-   **1.2.** Raw data description
-   **1.3.** Data cleaning
-   **1.4.** Total number of homicides and unsolved homicides
-   

**Problem 2**

-   **2.1.**
-   **2.2.**
-   **2.3.**
-   **2.4.**

**Problem 3**

-   **3.1.**
-   **3.2.**
-   **3.3.**
-   **3.4.**

## Problem 1

This problem uses data on homicides in 50 large U.S. cities gathered by
the *Washington Post*.

#### 1.1. Data import

The code below imports the raw data made available through a GitHub
repository.

``` r
# importing raw data from GitHub repository
hom_url <- 'https://raw.githubusercontent.com/washingtonpost/data-homicides/master/homicide-data.csv'
hom_read <- read_csv(url(hom_url), na = c(" ","Unknown", "NA"))
```

    ## Rows: 52179 Columns: 12

    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (8): uid, victim_last, victim_first, victim_race, victim_sex, city, stat...
    ## dbl (4): reported_date, victim_age, lat, lon

    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

#### 1.2. Raw data description

The **raw** dataset has **52179** observations and **12** variables,
including the *reported date* of the homicide; the *name*, *race*,
*age*, and *sex* of the victim; and the *city*, *state*, and *longitude*
and *latitude* of the homicide. Note that there is a possible data entry
error of 1 observation reported as being in *Tulsa, AL* (which does not
exist; *Tulsa* is in *OK*).

#### 1.3. Data cleaning

The following code chunk **cleans the data** by:

-   creating a `city_state` variable which combines city and state
-   creating a `resolution` variable indicating if a case was closed
    with or without arrest
-   excluding the 1 observation reported as being in *Tulsa, AL*

``` r
homicide_df = 
  hom_read %>%
  mutate(
    city_state = str_c(city, state, sep = ", "),
    resolution = case_when(
      disposition == "Closed without arrest" ~ "unsolved",
      disposition == "Open/No arrest"        ~ "unsolved",
      disposition == "Closed by arrest"      ~ "solved")) %>% 
  relocate(city_state) %>% 
  filter(city_state != "Tulsa, AL") 
```

The **new, cleaned** dataset has **52178** observations and **14**
variables.

#### 1.4. Total number of homicides and unsolved homicides

The next code chunk summarizes ***within cities*** to obtain:

1.  The **total** number of homicides
2.  The number of **unsolved** homicides (those for which the
    disposition is “Closed without arrest” or “Open/No arrest”).

``` r
cities_df = 
  homicide_df %>% 
  select(city_state, disposition, resolution) %>% 
  group_by(city_state) %>% 
  summarize(
    unsolved = sum(resolution == "unsolved"),
    n = n())
```

Focusing on the city of *Baltimore, MD*, we use the `prop.test` function
to estimate the proportion of homicides that are unsolved and the
`broom::tidy` function to pull the estimated proportion and confidence
intervals from the resulting dataframe.

``` r
baltimore_df =
  homicide_df %>% 
  filter(city_state == "Baltimore, MD")

baltimore_summary = 
  baltimore_df %>% 
  summarize(
    unsolved = sum(resolution == "unsolved"),
    n = n())

 baltimore_test =
   prop.test(
    x = baltimore_summary %>% pull(unsolved), 
    n = baltimore_summary %>% pull(n))

baltimore_test %>% 
  broom::tidy() %>% 
  knitr::kable(digits = 4)
```

| estimate | statistic | p.value | parameter | conf.low | conf.high | method                                               | alternative |
|---------:|----------:|--------:|----------:|---------:|----------:|:-----------------------------------------------------|:------------|
|   0.6456 |   239.011 |       0 |         1 |   0.6276 |    0.6632 | 1-sample proportions test with continuity correction | two.sided   |

Next, we run `prop.test` for each of the cities in the dataset, and
extract both the proportion of unsolved homicides and the confidence
interval for each. This is done within a “tidy” pipeline, making use of
`purrr::map`, `purrr::map2`, and `unnest` as necessary to create a tidy
dataframe with **estimated proportions** and \*\*CIs\* for each city.

``` r
results_df = 
  cities_df %>% 
  mutate(test_results = map2(.x = unsolved, .y = n, ~prop.test(x = .x, n = .y)),
         tidy_results = map(test_results, broom::tidy)) %>% 
  select(-test_results) %>% 
  unnest(tidy_results) %>% 
  select(city_state, estimate, starts_with("conf"))
```

The code chunk below creates a plot that shows the estimates and CIs for
each city – and uses `geom_errorbar` to add error bars based on the
upper and lower limits. Cities are organized according to the proportion
of unsolved homicides.

``` r
results_df %>% 
  mutate(city_state = fct_reorder(city_state, estimate)) %>% 
  ggplot(aes(x = city_state, y = estimate)) + 
  geom_point(color = "darkred") + 
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1),
        plot.title = element_text(face = "bold.italic" )) +
  labs(title = "Figure 1: Proportion of unsolved cases in 50 major US cities", 
       y = "Estimated Proportion of Unsolved Homicides", 
       x = "City", 
       caption = "*Note: Error bars indicate 95% confidence interval")
```

<img src="p8105_hw5_jys2137_files/figure-gfm/unnamed-chunk-5-1.png" width="90%" />

***Figure 1*** illustrates that across the 50 major U.S. cities, rates
at which homicides are solved vary greatly. Notably, **Chicago, IL** has
a distinctly high proportion of unsolved homicides, at **over 0.7**.
This unfortunately makes sense, as Chicago is a city with a high rate of
homicides overall. In stark comparison, the lowest proportion of
unsolved homicides is in **Richmond, VA**, at just above **0.25**.
